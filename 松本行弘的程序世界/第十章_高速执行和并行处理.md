# 第十章 高速执行和并行处理

### 让程序高速执行(前篇)

#### 并不是越快越好

如果总是视速度最重要,那么久总得准备最高速的机器.或许,还需要用能够编写最高速程序的低级语言(比如汇编)来写程序.

性能需要权衡.通常,程序能在必要的时间内执行完毕就足够了.一味追求高速而什么制约因素都不考虑不可求.

#### 高速执行的乐趣与效率

工作中在进行性能优化之前,必须要确认是否真有必要提高速度.速度提高到什么程度也要事先估算.

#### 以数据为基础做出判断

执行命令在开始加上 `time` 就可以.

		cat test.sh
		#!/bin/bash
		
		sleep 2
		
		[ansible@rancher-server ~]$ time ./test.sh

		real	0m2.004s
		user	0m0.001s
		sys	0m0.002s
		
* `real` 总执行时间. 程序从开始到终止的执行时间. 有时称为 total 或者 elapsed (经过时间).
* `user` 用户消费时间. 程序执行中,用户所消费的时间,即程序本身的执行时间.
* `sys` 系统消费时间. 程序执行中,系统调用(system call)所花费的时间,有时称为 system

可以根据 `user` 和 `sys` 判断是程序本身执行慢,还是系统调用太多而导致了程序变慢.

通常,程序工作的用户空间与系统调用所工作的内核空间是完全隔离的,所以系统调用需要遵循以下几个步骤:

1. 将参数从用户空间复制到内核空间
2. 执行系统调用的中断程序
3. 在中断处理内切换到内核空间.

将系统调用的结果返回用户控件又需要反方向执行这几步.

#### 改善系统调用 

作者在这里举例是用文件的更新时间来排序.第一个例子: 每次比较都需要调用File.mtime(文件),系统调用也比较久.

**施瓦茨变换**

先计算出比较用的值,避免比较计算重复进行.也就是通过事先保存反复计算的值来削减了计算量.以空间交换时间.

也就是先计算出 文件的 mtime 值,在比较.在使用后程序的执行速度快乐 17 倍.

#### 数据可靠吗

Linux 多任务操作系统 CPU 始终用于执行多个进程. 所以,用 time 所测的总执行时间会受到其他进程的影响.==用户消费时间加上系统消费时间与总执行时间不一致==.

根据操作系统的缓存与换页的不同,执行同样的命令,执行时间有可能极为不同.

在测定执行速度时:

* 避免测定太短的时间
* 反复测定(观察总体倾向)

#### 只需改善瓶颈

**帕累托法则**

又称为 `80/20` 法则, 即 80% 的数值是由 20% 的构成要素产生的.

**瓶颈**

通常一半以上的执行时间都耗费在程序中不到 4% 的部分.

这些耗费了大半以上执行时间的部分称为瓶颈.

#### 理解 O记法

* O(1) 数组访问. 哈希法
* O(log(n)) binary search
* O(n) 字符串比较
* O(n \* log(n)) quick sort
* O(n^2) 冒泡排序
* O(n^3) 行列乘法运算
* O(2^n) 集合分割问题

O记法只能表示随着元素个数的增加,该算法的大体走向.O(n^2) 表示数据量变成 10 倍的时候执行时间按元素个数的2次方比例增长这一==趋势==.

#### 高速执行的悲哀

**徒劳无益的努力**

很容易在跟瓶颈无关的地方花费太多徒劳无益的努力.

**改良绊住了手脚**

**算法选择的圈套**

可能底层函数就有更好的实现(C语言)

#### 性能优化的格言

* 过早的优化是万恶之源
* 优化有两条准则
	* 别做优化
	* (仅适用于专家) 先不要做优化

### 让程序高速执行(后篇)
