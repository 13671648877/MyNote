# 第十章 高速执行和并行处理

### 让程序高速执行(前篇)

#### 并不是越快越好

如果总是视速度最重要,那么久总得准备最高速的机器.或许,还需要用能够编写最高速程序的低级语言(比如汇编)来写程序.

性能需要权衡.通常,程序能在必要的时间内执行完毕就足够了.一味追求高速而什么制约因素都不考虑不可求.

#### 高速执行的乐趣与效率

工作中在进行性能优化之前,必须要确认是否真有必要提高速度.速度提高到什么程度也要事先估算.

#### 以数据为基础做出判断

执行命令在开始加上 `time` 就可以.

		cat test.sh
		#!/bin/bash
		
		sleep 2
		
		[ansible@rancher-server ~]$ time ./test.sh

		real	0m2.004s
		user	0m0.001s
		sys	0m0.002s
		
* `real` 总执行时间. 程序从开始到终止的执行时间. 有时称为 total 或者 elapsed (经过时间).
* `user` 用户消费时间. 程序执行中,用户所消费的时间,即程序本身的执行时间.
* `sys` 系统消费时间. 程序执行中,系统调用(system call)所花费的时间,有时称为 system

可以根据 `user` 和 `sys` 判断是程序本身执行慢,还是系统调用太多而导致了程序变慢.

通常,程序工作的用户空间与系统调用所工作的内核空间是完全隔离的,所以系统调用需要遵循以下几个步骤:

1. 将参数从用户空间复制到内核空间
2. 执行系统调用的中断程序
3. 在中断处理内切换到内核空间.

将系统调用的结果返回用户控件又需要反方向执行这几步.

#### 改善系统调用 

作者在这里举例是用文件的更新时间来排序.第一个例子: 每次比较都需要调用File.mtime(文件),系统调用也比较久.

**施瓦茨变换**

先计算出比较用的值,避免比较计算重复进行.也就是通过事先保存反复计算的值来削减了计算量.以空间交换时间.

也就是先计算出 文件的 mtime 值,在比较.在使用后程序的执行速度快乐 17 倍.

#### 数据可靠吗

Linux 多任务操作系统 CPU 始终用于执行多个进程. 所以,用 time 所测的总执行时间会受到其他进程的影响.==用户消费时间加上系统消费时间与总执行时间不一致==.

根据操作系统的缓存与换页的不同,执行同样的命令,执行时间有可能极为不同.

在测定执行速度时:

* 避免测定太短的时间
* 反复测定(观察总体倾向)

#### 只需改善瓶颈

**帕累托法则**

又称为 `80/20` 法则, 即 80% 的数值是由 20% 的构成要素产生的.

**瓶颈**

通常一半以上的执行时间都耗费在程序中不到 4% 的部分.

这些耗费了大半以上执行时间的部分称为瓶颈.

#### 理解 O记法

* O(1) 数组访问. 哈希法
* O(log(n)) binary search
* O(n) 字符串比较
* O(n \* log(n)) quick sort
* O(n^2) 冒泡排序
* O(n^3) 行列乘法运算
* O(2^n) 集合分割问题

O记法只能表示随着元素个数的增加,该算法的大体走向.O(n^2) 表示数据量变成 10 倍的时候执行时间按元素个数的2次方比例增长这一==趋势==.

#### 高速执行的悲哀

**徒劳无益的努力**

很容易在跟瓶颈无关的地方花费太多徒劳无益的努力.

**改良绊住了手脚**

**算法选择的圈套**

可能底层函数就有更好的实现(C语言)

#### 性能优化的格言

* 过早的优化是万恶之源
* 优化有两条准则
	* 别做优化
	* (仅适用于专家) 先不要做优化

### 让程序高速执行(后篇)

#### 规则1: 减少对象

对象的生成要花费一定的成本(时间).

#### 规则2: 减少方法调用

#### 高速优化之二: 利用立即值

#### 高速优化之三: 利用C语言

#### 高速优化之四: 采用合适的数据结构

#### 总结

过早的优化是万恶之源.

### 并行编程

**并发**

一个CPU, 但操作系统能够将程序的执行单位细化,然后分开执行,从而实现伪并行执行.

**并行**

多个CPU真的同时执行称为并行

#### 使用多线程理由

配置了专用内存空间的程序执行代码称为进程,进程中也包含 CPU 状态.

进程之间的通信:

* 管道: pipe 把某一程序(进程)的标准输出传给另一进程,作为其标准输入的一种参数传递方法.

		cat file | more
		
* 套接字: socket 是像操作文件一样,处理网络通信的一种机制.
* 字节流: 是单向或者双向数据通信时的一个概念.发信端和收信端数据的排列是一致的.
* 共享内存: 是指多个进程之间能够共享的内存.虽然高速,但缺点是需要有防止冲突的机制,不易取得更新时机.

**使用线程**

内存空间之所以独立,是因为要保护进程,避免进程之间互相干扰.但进程之间的通信较为繁琐.

==一个进程由一个以上的线程构成==

使用线程可以在一个进程中同时进行多个处理. thread(线程) 元一是缝衣线的意思.执行流程像缝在衣服上的线一样,一会出现,一会消失.

==统一进程的线程可以共享内存空间.==

#### 信息共享所产生的问题

并行处理本身的问题:

* 数据完整性的丧失
* 死锁

#### 数据完整性的丧失

线程之间共享同一内存空间,可能无意间同时访问了同一变量或同一对象.这就会发生数据完整性的丧失.

==原子性==,不能分割的处理.

#### 死锁

死锁,是指多个线程互相争夺资源,谁也动不了的状态.

由于某种竞争,处理永远陷入停止状态,我们称之为死锁.

多个并行处理共享的资源(称为 resource)不足的时候,如果访问步骤考虑不周的话,就会引起死锁.

#### 用锁来实现对资源的独占

规避资源的同时访问,其中最简单的是独占使用中的资源.

#### 二级互斥

#### 用队列协调线程

线程间信息交换的方法有很多种,有代表性的有消息存储(message banking),信道(channel)以及队列(queue).

**生产者-消费者模型**

某一线程制作数据,另以县城通过队列获取数据,然后进行下一步处理.

制作数据的线程称为生产者(producer),获取数据的线程称为消费者(consumer)


		生产者线程 --> 队列 --> 消费者线程
		
#### 锁模型与队列模型的比较

**锁模型**

如果竞争足够少,多数情况下能保持较高性能.但是,对于资源的竞争,不能忘记加锁.要做到完美无缺较难.

**队列模型**

在竞争少的时候,其性能比不上锁模型.它比锁模型更容易贯彻.这种方法很少会因为线程增多而带来性能底下的恶果.

### 前景可期的并行编程技术, Actor

"Actor Model" 参与者模式

#### 何谓Actor

`Actor`,是(仅) 通过消息 (message)进行通信的实体.

**与面向对象语言的对象区别**

像对象发送消息(方法调用),调用开始后,会一致等到返回结果,是一种==同步方式==.

而向`Actor`发送消息,仅仅是发送消息而不等返回结果,是一种==异步方式==.

#### 操作Actor的 3 种处理系统

#### Erlang的错误处理

对于有扩展性的系统,重要的是,即使发生了异常事态,也不至于全体系统都停止.

Erlang 中,通过发送消息来通知异常终止.通过`link`机制将`process`与`process链接(link)`起来.被链接起来的`process`在终止之前,往链接目标发送消息说"我要死了".收到消息的`process`料理死去的`process`的后事.

#### Erlang的适用场所

`Eralng`的好处还是其扩展性.对于多个处理并列执行的情况,分割成合适的`Erlang process`,能够发挥多`CPU`的威力.

`Eralng`特别适合对于大量的请求进行非同步处理的任务.


		

