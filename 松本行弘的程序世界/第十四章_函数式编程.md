# 第十四章 函数式编程

### 新范型 函数式编程

函数式编程是全部使用函数来编写程序代码的编程方式.

**特征**

* 函数本身也作为数据来处理(第一级函数)
* 以函数为参数的高阶函数
* 参数相同即可保证结果相同的引用透明性
* 为实现引用透明,进制产生副作用的处理

**示例**

阶乘计算:

```php
结构化:
def fact(n)
	fct = 1
	while n > 1
		fct = fct * n
		n = n-1
	end
	fct
end

函数式
def fact(n)
	if n == 1
		1
	else
		n * fact(n-1)
	end
end
```

函数式编程可以把算法写得非常==接近于数学的表达形式==.

**声明式编程**

函数式编程不包含状态或者动作等信息,仅仅是对想要做什么加以描述.

这种不是描述动作,而是描述性质的编程方式称为==声明式编程==.

声明式描述是函数式编程的一大优点.

#### 具有多种函数性质的 Lisp

函数本身也作为数据来处理,具有函数的第一级性质.

`S式记法`, Lisp 的函数定义,数据结构定义,算式以及流程控制等全都采用这种形式.

`Lisp` 语言本名是 `List Processor` 链表处理器.

`链`是一种构成树结构数据的通用数据结构,构成数据结构的节点分别包含两个引用.

Lisp 把节点称为`cons`单元:

* 第一个引用称为`car`
* 第二个引用称为`cdr`

`cons` 这种叫法来自生成新单元的函数`cons`.因为最初 Lisp 处理器把 car 数据放在 ==地址寄存器==, 把 cdr 数据放在数据寄存器. 所以 `contents of address register`(地址寄存器内容)省略为`car`, `contents of data register`(数据寄存器内容)省略为`cdr`.

`cons` 单元一位构成链的数据元素(符号,数值等)称为原子(atom).

链就是 atom 和 cons 单元构成树形数据结构.

函数式编程常常通过自我调用来实现递归调用.

#### 彻底的函数式编程语言 Haskell

Haskell 语言有如下特征:

* 没有副作用
* 高阶函数
* 函数部分应用
* 延迟计算
* 静态多态类型系统
* 型推论
* 链内包表达式
* 用对齐来表示块

==无副作用==: 不能改变变量的值,就连链的元素也是不能改变的.

Haskell 程序中看起来像是变量的名字,实际上不过是函数参数或是值得别名.不存在作为保存变量值的变量.

Haskell 没有赋值,只有给式命名,称为绑定.其他语言中改变变量值的处理,都对应重新生成一部分发生变化的新数据.

==引用透明性==: 没有变量,任何值都不会发生变化.因此,只要参数不变,函数的返回值也就总是一样的.相同输入总能返回相同的结果,这种重复性也称为引用透明性.

#### 延迟计算: 不必要的处理就不做

**优点**

具有延迟计算性质的编程语言在字面上的意思与书记处理是不一样的.不进行多余的处理,即使是无限连续的数据也能处理.

**缺点**

程序的语句与实际的处理不是直接对应的,很难判断问题出在什么地方.

#### 灵活的"静态多态性"类型系统

Haskell 是在编译时确定所有变量类型的静态类型语言.但是 Haskell 语言处理系统会推测变量的类型.

动态类型语言不进行这样的类型检查,显得非常宽容,只要拥有相同的方法,什么对象都可以,这就带来了柔软性,这种风格称为 duck typing.

Haskell 维持着姐姐与 duck typing 灵活性的同时,也使编译时的完全类型检查称为可能.

#### 近代函数式语言之父OCaml

* 有副作用
* 没有延迟计算
* 具有强力的模块系统

#### 强于并行计算的 Erlang

函数式编程没有副作用. 改变数据时的同步处理是并行计算中最麻烦的部分,而如果根本就没有赋值,根本就不去改变数据的话,同步处理也就没有必要了.

Eralng 没有副作用,也不需要同步.

#### 用户Ruby进行函数式编程

### 自动生成代码

### 内存管理与垃圾收集

垃圾收集 (Garbage Collection, GC) 是一种管理程序使用的内存区域的方法.

使用具有垃圾收集功能的编程语言或处理程序的话,程序中不需要编写内存管理的代码,也就是说不用编写代码来释放使用过的内存区域.

#### 内存管理的困难

"手工"管理内存的方法,很容易发生各种问题:

**悬挂指针**

把还在使用中的内存区域错误地调用`free()`予以释放的话,就会发生悬挂指针(`dangling pointer`)的现象.

在此之后,错误释放了的内存区域可能被程序用于别的目的,或者返还给操作系统.会脱离程序管理,编程预想之外的状态.

这样,程序再去访问该区域的时候就会出错.或者置换成预想之外的数据.

**内存泄露**

忘记了吧申请的内存区域返还给操作系统的话,就会发生内存泄露(`memory leak`).这时候因为使用过的内存区域越积越多,程序占有的内存就会逐渐增加.特别是长时间启动,连续提供服务的常驻内存型程序(daemon).

**二重释放**

对已经释放过的内存区域再次调用`free()`的情况称为二重释放(double free).
这回带来`malloc()`和`free()`内部使用的数据区域不一致的问题.

**垃圾收集性能的指标**

==吞吐量== `throughput` 是垃圾收集处理在程序全部执行时间中所占的比例. 垃圾收集处理所占的比例越小越好,垃圾收集处理所占的比例大的话(吞吐量小),程序整体的性能就会低下.

==暂停时间== `pause time` 是一次垃圾收集处理所中断的时间.

* 把垃圾收集时间求平均所得的平均暂停时间.
* 程序执行中最长的垃圾收集时间所代表的最大暂停时间.

#### 垃圾收集算法

* 引用计数法(php 使用)
* 标记和扫除方式
* 标记和紧缩方式
* 复制方式

#### 引用计数法

php 使用.

个对象知道自己被从几个地方引用着(被引用数,引用计数器).然后,在引用增减的同时也相对地改变被引用数.引用计数器变成 0 的对象,也就明确地表明它不在被其他对象所引用,可以释放它所占用的内存区域.

**优点**

暂停时间短

**缺点**

* 不能释放有循环引用关系的对象群(相互引用)
* 引用增减的时候有必要同时正确维护引用计数器的增减.
* 引用计数器的管理与并行处理不相容.

#### 标记和扫除方式 

ruby 使用

* 从根开始按顺序给所有被用用的对象加上标记
* 没有标记的对象被释放

#### 标记和紧缩方式

标记处理 和 扫除方式 一致, 后阶段不同.

标记和紧缩方式移动生存中的对象位置来腾出空间.

把空间其中起来(紧缩). 紧缩的结果是把没有释放而活下来的对象都集中到了一个地方.这样,内存访问就集中到一个局部区域,这可以提高缓存功能的效率.

缺点: 把生存着的对象全部复制的紧缩开销,容易比交际和扫除方式中执行扫除的开销还要大.还因为对象被移动位置了,不能应用下文讲述的保守垃圾收集.

#### 复制方式

上述的两种方式:

* 标记时间与活着的对象数称比例.
* 扫除(或者缩紧)时间与总对象数称比例.

在分配有非常多的对象,其中几乎所有对象都被释放的场合,扫除的开销会非常高.

==复制方式== 回收内存区域,与生存者的对象成比例的开销.

**原理**

* 在旧空间里分配对象
* 旧空间填满的时候,从根开始扫描对象,把对象复制到新空间.

把内存空间分成 旧空间 和 新空间 两大块,总是在旧空间分配对象. 旧空间爆满的时候,从根开始扫描对象,把对象复制到新空间.(复制后的引用也要随之更新).

不再被引用的对象都遗留在旧空间,旧空间旧可以整个地弃之不用,也就避免了扫除的开销.从这之后再把新空间作为这次的旧空间来继续同样的处理.

**局部性优点**

复制方式按顺序把引用的对象复制到新空间,==关系近的对象会被分配在相近的内存空间上==,这称为局部性.

#### 多种多样的垃圾收集算法

* 分代垃圾收集
* 保守垃圾收集
* 增量垃圾收集
* 并行垃圾收集
* 位图标志

#### 分代垃圾收集





