# 第十四章 函数式编程

### 新范型 函数式编程

函数式编程是全部使用函数来编写程序代码的编程方式.

**特征**

* 函数本身也作为数据来处理(第一级函数)
* 以函数为参数的高阶函数
* 参数相同即可保证结果相同的引用透明性
* 为实现引用透明,进制产生副作用的处理

**示例**

阶乘计算:

```php
结构化:
def fact(n)
	fct = 1
	while n > 1
		fct = fct * n
		n = n-1
	end
	fct
end

函数式
def fact(n)
	if n == 1
		1
	else
		n * fact(n-1)
	end
end
```

函数式编程可以把算法写得非常==接近于数学的表达形式==.

**声明式编程**

函数式编程不包含状态或者动作等信息,仅仅是对想要做什么加以描述.

这种不是描述动作,而是描述性质的编程方式称为==声明式编程==.

声明式描述是函数式编程的一大优点.

#### 具有多种函数性质的 Lisp

函数本身也作为数据来处理,具有函数的第一级性质.

`S式记法`, Lisp 的函数定义,数据结构定义,算式以及流程控制等全都采用这种形式.

`Lisp` 语言本名是 `List Processor` 链表处理器.

`链`是一种构成树结构数据的通用数据结构,构成数据结构的节点分别包含两个引用.

Lisp 把节点称为`cons`单元:

* 第一个引用称为`car`
* 第二个引用称为`cdr`

`cons` 这种叫法来自生成新单元的函数`cons`.因为最初 Lisp 处理器把 car 数据放在 ==地址寄存器==, 把 cdr 数据放在数据寄存器. 所以 `contents of address register`(地址寄存器内容)省略为`car`, `contents of data register`(数据寄存器内容)省略为`cdr`.

`cons` 单元一位构成链的数据元素(符号,数值等)称为原子(atom).

链就是 atom 和 cons 单元构成树形数据结构.

函数式编程常常通过自我调用来实现递归调用.

#### 彻底的函数式编程语言 Haskell

Haskell 语言有如下特征:

* 没有副作用
* 高阶函数
* 函数部分应用
* 延迟计算
* 静态多态类型系统
* 型推论
* 链内包表达式
* 用对齐来表示块

==无副作用==: 不能改变变量的值,就连链的元素也是不能改变的.

Haskell 程序中看起来像是变量的名字,实际上不过是函数参数或是值得别名.不存在作为保存变量值的变量.

Haskell 没有赋值,只有给式命名,称为绑定.其他语言中改变变量值的处理,都对应重新生成一部分发生变化的新数据.

==引用透明性==: 没有变量,任何值都不会发生变化.因此,只要参数不变,函数的返回值也就总是一样的.相同输入总能返回相同的结果,这种重复性也称为引用透明性.

#### 延迟计算: 不必要的处理就不做

**优点**

具有延迟计算性质的编程语言在字面上的意思与书记处理是不一样的.不进行多余的处理,即使是无限连续的数据也能处理.

**缺点**

程序的语句与实际的处理不是直接对应的,很难判断问题出在什么地方.

#### 灵活的"静态多态性"类型系统

Haskell 是在编译时确定所有变量类型的静态类型语言.但是 Haskell 语言处理系统会推测变量的类型.

动态类型语言不进行这样的类型检查,显得非常宽容,只要拥有相同的方法,什么对象都可以,这就带来了柔软性,这种风格称为 duck typing.

Haskell 维持着姐姐与 duck typing 灵活性的同时,也使编译时的完全类型检查称为可能.

#### 近代函数式语言之父OCaml

* 有副作用
* 没有延迟计算
* 具有强力的模块系统

#### 强于并行计算的 Erlang

函数式编程没有副作用. 改变数据时的同步处理是并行计算中最麻烦的部分,而如果根本就没有赋值,根本就不去改变数据的话,同步处理也就没有必要了.

Eralng 没有副作用,也不需要同步.

#### 用户Ruby进行函数式编程

### 自动生成代码

### 内存管理与垃圾收集

垃圾收集 (Garbage Collection, GC) 是一种管理程序使用的内存区域的方法.

使用具有垃圾收集功能的编程语言或处理程序的话,程序中不需要编写内存管理的代码,也就是说不用编写代码来释放使用过的内存区域.

#### 内存管理的困难

"手工"管理内存的方法,很容易发生各种问题:

**悬挂指针**

把还在使用中的内存区域错误地调用`free()`予以释放的话,就会发生悬挂指针(`dangling pointer`)的现象.

在此之后,错误释放了的内存区域可能被程序用于别的目的,或者返还给操作系统.会脱离程序管理,编程预想之外的状态.

这样,程序再去访问该区域的时候就会出错.或者置换成预想之外的数据.

**内存泄露**

忘记了吧申请的内存区域返还给操作系统的话,就会发生内存泄露(`memory leak`).这时候因为使用过的内存区域越积越多,程序占有的内存就会逐渐增加.特别是长时间启动,连续提供服务的常驻内存型程序(daemon).

**二重释放**

对已经释放过的内存区域再次调用`free()`的情况称为二重释放(double free).
这回带来`malloc()`和`free()`内部使用的数据区域不一致的问题.

**垃圾收集性能的指标**

==吞吐量== `throughput` 是垃圾收集处理在程序全部执行时间中所占的比例. 垃圾收集处理所占的比例越小越好,垃圾收集处理所占的比例大的话(吞吐量小),程序整体的性能就会低下.

==暂停时间== `pause time` 是一次垃圾收集处理所中断的时间.

* 把垃圾收集时间求平均所得的平均暂停时间.
* 程序执行中最长的垃圾收集时间所代表的最大暂停时间.

#### 垃圾收集算法

* 引用计数法(php 使用)
* 标记和扫除方式
* 标记和紧缩方式
* 复制方式

#### 引用计数法

php 使用.

个对象知道自己被从几个地方引用着(被引用数,引用计数器).然后,在引用增减的同时也相对地改变被引用数.引用计数器变成 0 的对象,也就明确地表明它不在被其他对象所引用,可以释放它所占用的内存区域.

**优点**

暂停时间短

**缺点**

* 不能释放有循环引用关系的对象群(相互引用)
* 引用增减的时候有必要同时正确维护引用计数器的增减.
* 引用计数器的管理与并行处理不相容.

#### 标记和扫除方式 

ruby 使用

* 从根开始按顺序给所有被用用的对象加上标记
* 没有标记的对象被释放

#### 标记和紧缩方式

标记处理 和 扫除方式 一致, 后阶段不同.

标记和紧缩方式移动生存中的对象位置来腾出空间.

把空间其中起来(紧缩). 紧缩的结果是把没有释放而活下来的对象都集中到了一个地方.这样,内存访问就集中到一个局部区域,这可以提高缓存功能的效率.

缺点: 把生存着的对象全部复制的紧缩开销,容易比交际和扫除方式中执行扫除的开销还要大.还因为对象被移动位置了,不能应用下文讲述的保守垃圾收集.

#### 复制方式

上述的两种方式:

* 标记时间与活着的对象数称比例.
* 扫除(或者缩紧)时间与总对象数称比例.

在分配有非常多的对象,其中几乎所有对象都被释放的场合,扫除的开销会非常高.

==复制方式== 回收内存区域,与生存者的对象成比例的开销.

**原理**

* 在旧空间里分配对象
* 旧空间填满的时候,从根开始扫描对象,把对象复制到新空间.

把内存空间分成 旧空间 和 新空间 两大块,总是在旧空间分配对象. 旧空间爆满的时候,从根开始扫描对象,把对象复制到新空间.(复制后的引用也要随之更新).

不再被引用的对象都遗留在旧空间,旧空间旧可以整个地弃之不用,也就避免了扫除的开销.从这之后再把新空间作为这次的旧空间来继续同样的处理.

**局部性优点**

复制方式按顺序把引用的对象复制到新空间,==关系近的对象会被分配在相近的内存空间上==,这称为局部性.

#### 多种多样的垃圾收集算法

* 分代垃圾收集
* 保守垃圾收集
* 增量垃圾收集
* 并行垃圾收集
* 位图标志

#### 分代垃圾收集

分代垃圾收集 (generational GC).

分代来及收集的基本思想史利用程序和对象的性质:

* 几乎所有的对象都在比较短的时间里编程垃圾
* 存活时间超过一定程度的对象总是拥有更长的寿命

==寿命长的对象更容易活下来,寿命短的对象会在更短时间内变成垃圾==.这样就可以中的概念分配之后还没怎么经过时间的"年轻的"对象进行扫描,不用扫描全部对象就可能高效率地回收垃圾.

把内存空间分成两个:

* 容纳年轻对象的"新代"用的区域
* 容纳长寿对象的"旧代"用的区域

**原理**

* 把寿命短的新代区域与寿命长的旧代区域分隔开来管理对象,用记录集来记录两者之间的引用
* 新代区域中引用关系的对象移到旧代区域中,释放没有引用关系的对象

**解决引用问题**

见识对象的更新,在旧代区域引用新代区域发生的同时,就把这一引用的记录例程以及对象的更新场所全都记录下来,这个检查历程叫做写屏障(`write barrier`). 记录旧代区域对新代区域的引用称为记录(`remembered set`).

**优缺点**

减少了扫描对象的个数,有缩短平均暂停时间的效果.

因为要执行全垃圾收集,最大展厅时间不会得到明显改善.

#### 保守垃圾收集

通常,垃圾收集的实现需要明确区分引用(指针),而 C 和 C++ 没有这样的功能,如果碰巧有整数与引用相同的话,该对象就有可能被引用,也就当它是活着的.==保守垃圾收集==

能够明确区别引用的环境下的垃圾收集称为精确垃圾收集(exact GC).

#### 增量垃圾收集

更重视最大暂停时间.在这类程序中,垃圾收集带来的中断时间必须是可以预测的.

为保证实时性,不需要等垃圾收集完全执行结束,而是要把垃圾收集处理细分成许多细小的片段,每次执行一点,这叫增量垃圾收集.

在垃圾收集处理过程中程序也在同时执行,引用有可能会改变.垃圾收集的一致性就不能得到保证.增量垃圾收集为避免这样的问题,采用了与保守垃圾收集相同的==写屏技术==.

#### 并行垃圾收集

并行垃圾收集就是要最大限度地利用多个 CPU 的能力.

原理与增量垃圾收集大致是一样的,都是利用写屏来维护当前状态的信息.有的并行垃圾收集的实现生成垃圾收集专用线程,把垃圾收集设计成总是与普通处理并行执行.

#### 位图标记

位图标记时在利用标记的垃圾收集中消减操作系统内存也复制的方法.它不在对象里设置被引用的标记,而是利用外部位图区域(管理用内存区域)来保存引用标记.

只有标记用的位图部分会发生内存页复制,从而避免了复制没有实际更新的对象所在内存页.(这种复制是因为 `cow` 写时复制, 类似 fork 子进程)

### 用 C 语言来扩展



#### 开发与执行速度的取舍

* 解释型语言: 执行速度慢但是开发周期快.
* 编译型语言: 开发周期容易变慢,执行速度高.

Ruby 解释器的构造:

* 字句解析器
* 语法解析器

### 为什么要开源 